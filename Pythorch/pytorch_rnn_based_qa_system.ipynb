{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "92JvvYftu_-c",
        "outputId": "901a147e-2b6a-4fe2-d4c6-0a191baaadcf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9bc46f0e-b5bf-4a08-9416-feeca9b1aaa5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bc46f0e-b5bf-4a08-9416-feeca9b1aaa5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bc46f0e-b5bf-4a08-9416-feeca9b1aaa5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bc46f0e-b5bf-4a08-9416-feeca9b1aaa5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9cb19aa1-820d-479e-9e18-254d78fc3b27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9cb19aa1-820d-479e-9e18-254d78fc3b27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9cb19aa1-820d-479e-9e18-254d78fc3b27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd # Import the pandas library, commonly aliased as 'pd', for data manipulation and analysis.\n",
        "\n",
        "df = pd.read_csv('../Data/100_Unique_QA_Dataset.csv') # Read the CSV file '100_Unique_QA_Dataset.csv' into a pandas DataFrame named 'df'. This DataFrame will hold our question-answer pairs.\n",
        "\n",
        "df.head() # Display the first 5 rows of the DataFrame 'df'. This is useful for quickly inspecting the data structure and content after loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NWdOVkZ1viJ3"
      },
      "outputs": [],
      "source": [
        "# Define a function called 'tokenize' that takes a 'text' string as input.\n",
        "def tokenize(text):\n",
        "  text = text.lower() # Convert the input text to lowercase to ensure uniformity and reduce vocabulary size (e.g., 'What' and 'what' are treated the same).\n",
        "  text = text.replace('?','') # Remove question marks from the text, as they are usually not relevant for tokenization in this context.\n",
        "  text = text.replace(\"'\",\"\") # Remove apostrophes from the text. This helps in standardizing words (e.g., 'don't' becomes 'dont').\n",
        "  return text.split() # Split the processed text into a list of words (tokens) based on whitespace. This returns a list of individual words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnGY1SR0v78p",
        "outputId": "8f6fbeeb-2b02-4071-f4ba-2fe2161aaea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize('What is the capital of France?') # Call the 'tokenize' function with a sample question string to demonstrate its functionality and see the tokenized output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "tld5UfhqvrRq"
      },
      "outputs": [],
      "source": [
        "# Initialize a dictionary called 'vocab'. This dictionary will store our vocabulary, mapping each unique word to a numerical index.\n",
        "vocab = {'<UNK>':0} # Start with a special token '<UNK>' (Unknown) and assign it the index 0. This token will be used for words not found in the vocabulary during inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XxpiMiXtw4oX"
      },
      "outputs": [],
      "source": [
        "# Define a function 'build_vocab' that takes a 'row' (presumably a row from a DataFrame containing 'question' and 'answer' columns) as input.\n",
        "def build_vocab(row):\n",
        "  tokenized_question = tokenize(row['question']) # Tokenize the 'question' text from the current row using the 'tokenize' function.\n",
        "  tokenized_answer = tokenize(row['answer']) # Tokenize the 'answer' text from the current row using the 'tokenize' function.\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer # Combine the tokenized question and answer into a single list of tokens. This ensures all words from both are considered for the vocabulary.\n",
        "\n",
        "  for token in merged_tokens: # Iterate through each token in the combined list.\n",
        "\n",
        "    if token not in vocab: # Check if the current token is not already present in the 'vocab' dictionary.\n",
        "      vocab[token] = len(vocab) # If the token is new, add it to the 'vocab' dictionary and assign it a new unique index, which is the current size of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "9LSxaRRuxHlv",
        "outputId": "480f2786-7511-4313-91e5-480d9d58f682"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.apply(build_vocab, axis=1) # Apply the 'build_vocab' function to each row of the DataFrame 'df'. 'axis=1' ensures the function is applied row-wise, processing each question-answer pair to build the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDWgT_OoyGJM",
        "outputId": "d76c5fa7-7f44-493c-b66f-0cfc29d2ee5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab) # Print the total number of unique words (tokens) collected in the 'vocab' dictionary after processing all the data. This indicates the size of our vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BUBXvBNovvQa"
      },
      "outputs": [],
      "source": [
        "# Define a function 'text_to_indices' that converts a given 'text' into a list of numerical indices based on the provided 'vocab' dictionary.\n",
        "def text_to_indices(text, vocab):\n",
        "\n",
        "  indexed_text = [] # Initialize an empty list to store the numerical indices of the tokens.\n",
        "\n",
        "  for token in tokenize(text): # Tokenize the input text using the 'tokenize' function and iterate through each resulting token.\n",
        "\n",
        "    if token in vocab: # Check if the current token exists in our established 'vocab' dictionary.\n",
        "      indexed_text.append(vocab[token]) # If the token is in the vocabulary, append its corresponding numerical index to 'indexed_text'.\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>']) # If the token is not found in the vocabulary, append the index of the '<UNK>' (Unknown) token.\n",
        "\n",
        "  return indexed_text # Return the list of numerical indices representing the input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phdJw6IQzax2",
        "outputId": "c2e1e080-e46a-4d95-8d7d-fcb2c4beec79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_indices(\"What is campusx\", vocab) # Test the 'text_to_indices' function with a sample phrase \"What is campusx\" and our 'vocab' to see how it converts words into numerical representations. 'campusx' is likely not in the vocab, so it will be mapped to '<UNK>'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "k-haYG7WzjHj"
      },
      "outputs": [],
      "source": [
        "import torch # Import the PyTorch library, a popular open-source machine learning framework.\n",
        "from torch.utils.data import Dataset, DataLoader # Import 'Dataset' and 'DataLoader' classes from PyTorch's data utilities. 'Dataset' is an abstract class representing a dataset, and 'DataLoader' provides an iterable over a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PElUlPYT0gqK"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset): # Define a custom dataset class named 'QADataset' that inherits from PyTorch's 'Dataset'. This class will handle loading and preprocessing our QA data.\n",
        "\n",
        "  def __init__(self, df, vocab): # The constructor method for the QADataset class, taking a DataFrame 'df' and the 'vocab' dictionary as inputs.\n",
        "    self.df = df # Store the input DataFrame 'df' as an instance variable.\n",
        "    self.vocab = vocab # Store the input vocabulary dictionary 'vocab' as an instance variable.\n",
        "\n",
        "  def __len__(self): # This method returns the total number of samples (rows) in the dataset.\n",
        "    return self.df.shape[0] # Return the number of rows in the DataFrame, which corresponds to the number of question-answer pairs.\n",
        "\n",
        "  def __getitem__(self, index): # This method retrieves a single sample (question-answer pair) given an 'index'.\n",
        "\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab) # Convert the 'question' text of the row at the given 'index' into a list of numerical indices using 'text_to_indices' and the stored vocabulary.\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab) # Convert the 'answer' text of the row at the given 'index' into a list of numerical indices.\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer) # Convert the lists of numerical indices for question and answer into PyTorch tensors and return them as a pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "InSZ-ZIm1Y1O"
      },
      "outputs": [],
      "source": [
        "dataset = QADataset(df, vocab) # Create an instance of our 'QADataset' class, passing in the DataFrame 'df' and the 'vocab' dictionary. This prepares our data for use with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BMVDt3h-1gMF"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True) # Create a 'DataLoader' instance. It will load data from our 'dataset' in batches. 'batch_size=1' means one sample per batch, and 'shuffle=True' shuffles the data at each epoch for better training performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40MDNe0v1iMN",
        "outputId": "2939d0bc-02d8-435e-fe26-389b8c8a599e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 10,  29, 130, 131]]) tensor([132])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([113])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([9])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([259])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([188])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([134])\n",
            "tensor([[ 10,  75, 111]]) tensor([112])\n",
            "tensor([[10, 96,  3, 97]]) tensor([98])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([194])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([207])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([162])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([32])\n",
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([287])\n",
            "tensor([[10, 75, 76]]) tensor([77])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([68])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([36])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([244])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([173])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([23])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([53])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([74])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([268])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([61])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([220])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([116])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([114])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([185])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([205])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([321])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([16])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([52])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([254])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([121])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([225])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([102])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([249])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([311])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([36])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([72])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([106])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([58])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([215])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([298])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([205])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([65])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([154])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([100])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([110])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([28])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([49])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([233])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([54])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([149])\n",
            "tensor([[ 10,  75, 208]]) tensor([209])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([166])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([36])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([260])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([41])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([95])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([316])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([99])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([121])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([307])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([128])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([91])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([145])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([85])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([136])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([124])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([317])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([285])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([191])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([276])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([160])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([7])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([6])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([295])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([184])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([179])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([246])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([156])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([170])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([280])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([199])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([155])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([131])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([240])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([238])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([85])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([273])\n"
          ]
        }
      ],
      "source": [
        "for question, answer in dataloader: # Iterate through the 'dataloader' to get batches of questions and answers.\n",
        "  print(question, answer[0]) # Print the tensor representing the numerical question and the first element of the answer tensor. Since batch_size is 1, answer[0] gives the single answer tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SrJNCywq14Qv"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn # Import the 'torch.nn' module, which contains classes for building neural networks in PyTorch (e.g., layers, activation functions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y2XLQyi6GN61"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module): # Define a neural network class named 'SimpleRNN' that inherits from 'nn.Module', the base class for all neural network modules in PyTorch.\n",
        "\n",
        "  def __init__(self, vocab_size): # Constructor for the SimpleRNN model, taking 'vocab_size' (the total number of unique words in our vocabulary) as input.\n",
        "    super().__init__() # Call the constructor of the parent class (nn.Module). This is essential for proper initialization of PyTorch modules.\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50) # Define an embedding layer. This layer converts input integer indices (words) into dense, fixed-size vectors (embeddings) of size 50.\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True) # Define a simple Recurrent Neural Network (RNN) layer. It takes input features of size 50 (from the embedding layer) and produces hidden states of size 64. 'batch_first=True' means the input tensor's batch dimension comes first.\n",
        "    self.fc = nn.Linear(64, vocab_size) # Define a fully connected (linear) layer. It takes the 64-dimensional hidden state from the RNN and projects it to 'vocab_size' dimensions, representing the probability distribution over the vocabulary for the output word.\n",
        "\n",
        "  def forward(self, question): # The forward pass method, defining how data flows through the network. It takes a 'question' tensor (numerical indices) as input.\n",
        "    embedded_question = self.embedding(question) # Pass the 'question' tensor through the embedding layer to get word embeddings.\n",
        "    hidden, final = self.rnn(embedded_question) # Pass the embedded question through the RNN layer. 'hidden' contains the output for each step, and 'final' is the final hidden state (or cell state for LSTMs/GRUs). For a simple RNN, 'final' is typically the last hidden state.\n",
        "    output = self.fc(final.squeeze(0)) # Pass the final hidden state from the RNN through the fully connected layer. 'final.squeeze(0)' removes the batch dimension if it's a single element (e.g., from (1, 1, 64) to (1, 64)).\n",
        "\n",
        "    return output # Return the output from the fully connected layer, which represents the model's prediction for the answer word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al9891aUW0e_",
        "outputId": "bdfd6b20-22b1-4052-f859-60ad3455e3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape of a: torch.Size([1, 6])\n",
            "shape of b: torch.Size([1, 6, 50])\n",
            "shape of c: torch.Size([1, 6, 64])\n",
            "shape of d: torch.Size([1, 1, 64])\n",
            "shape of e: torch.Size([1, 324])\n"
          ]
        }
      ],
      "source": [
        "x = nn.Embedding(324, embedding_dim=50) # Create an example embedding layer with a vocabulary size of 324 and embedding dimension of 50.\n",
        "y = nn.RNN(50, 64, batch_first=True) # Create an example RNN layer with input size 50, hidden size 64, and batch_first set to True.\n",
        "z = nn.Linear(64, 324) # Create an example linear layer that maps from 64 features to 324 output features.\n",
        "\n",
        "a = dataset[0][0].reshape(1,6) # Take the first question from the dataset, which is a tensor, and reshape it to a batch size of 1 and sequence length of 6. This simulates an input to the model.\n",
        "print(\"shape of a:\", a.shape) # Print the shape of the reshaped input tensor 'a'.\n",
        "b = x(a) # Pass the reshaped input 'a' through the embedding layer 'x'.\n",
        "print(\"shape of b:\", b.shape) # Print the shape of the tensor 'b' after embedding. It should be (batch_size, sequence_length, embedding_dim).\n",
        "c, d = y(b) # Pass the embedded tensor 'b' through the RNN layer 'y'. 'c' will be the output from all time steps, and 'd' will be the final hidden state.\n",
        "print(\"shape of c:\", c.shape) # Print the shape of 'c' (output of RNN for all time steps).\n",
        "print(\"shape of d:\", d.shape) # Print the shape of 'd' (final hidden state of RNN).\n",
        "\n",
        "e = z(d.squeeze(0)) # Pass the final hidden state 'd' (after squeezing out the sequence length dimension if it's 1) through the linear layer 'z'.\n",
        "\n",
        "print(\"shape of e:\", e.shape) # Print the shape of 'e', which is the final output of the model before activation, typically (batch_size, vocab_size)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sk9pltE_KVgl"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001 # Set the learning rate for the optimizer. This value determines the step size at each iteration while moving toward a minimum of the loss function.\n",
        "epochs = 20 # Set the number of training epochs. An epoch means one complete pass through the entire training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "o-GmwXoHLpEw"
      },
      "outputs": [],
      "source": [
        "model = SimpleRNN(len(vocab)) # Instantiate our 'SimpleRNN' model. We pass the size of our vocabulary (len(vocab)) to the model's constructor, which is used to define the embedding and output layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "-pd_QgE8Lu90"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss() # Define the loss function. 'nn.CrossEntropyLoss()' is commonly used for multi-class classification problems, such as predicting a word from a vocabulary. It combines LogSoftmax and NLLLoss.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Define the optimizer. 'torch.optim.Adam' is an optimization algorithm that updates model weights during training. It takes the model's parameters and the specified 'learning_rate'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKITUSEnL-ol",
        "outputId": "6aa3d94b-b8c2-4549-9652-94c9f07cabd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 526.866436\n",
            "Epoch: 2, Loss: 455.015809\n",
            "Epoch: 3, Loss: 376.643435\n",
            "Epoch: 4, Loss: 317.801134\n",
            "Epoch: 5, Loss: 268.262268\n",
            "Epoch: 6, Loss: 221.662940\n",
            "Epoch: 7, Loss: 179.073948\n",
            "Epoch: 8, Loss: 141.565675\n",
            "Epoch: 9, Loss: 109.871347\n",
            "Epoch: 10, Loss: 84.316274\n",
            "Epoch: 11, Loss: 65.380416\n",
            "Epoch: 12, Loss: 51.709098\n",
            "Epoch: 13, Loss: 40.875442\n",
            "Epoch: 14, Loss: 32.925297\n",
            "Epoch: 15, Loss: 27.025303\n",
            "Epoch: 16, Loss: 22.561723\n",
            "Epoch: 17, Loss: 18.951467\n",
            "Epoch: 18, Loss: 16.034594\n",
            "Epoch: 19, Loss: 13.633483\n",
            "Epoch: 20, Loss: 11.900106\n"
          ]
        }
      ],
      "source": [
        "# Training loop: This block iterates over the dataset multiple times (epochs) to train the model.\n",
        "\n",
        "for epoch in range(epochs): # Loop for the specified number of 'epochs'.\n",
        "\n",
        "  total_loss = 0 # Initialize 'total_loss' to 0 at the beginning of each epoch to accumulate the loss over all batches.\n",
        "\n",
        "  for question, answer in dataloader: # Iterate through each batch in the 'dataloader'. Each batch contains a 'question' tensor and an 'answer' tensor.\n",
        "\n",
        "    optimizer.zero_grad() # Clear the gradients of all optimized tensors. This is crucial before each backward pass to prevent gradient accumulation from previous iterations.\n",
        "\n",
        "    # forward pass\n",
        "    output = model(question) # Perform a forward pass: feed the 'question' tensor to the model to get its predictions ('output').\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(output, answer[0]) # Calculate the loss between the model's 'output' (predictions) and the true 'answer'. 'answer[0]' is used because our batch size is 1, and the answer tensor might have an extra dimension.\n",
        "\n",
        "    # gradients\n",
        "    loss.backward() # Perform a backward pass: compute the gradients of the loss with respect to the model's parameters.\n",
        "\n",
        "    # update\n",
        "    optimizer.step() # Update the model's parameters using the computed gradients and the optimizer's update rules.\n",
        "\n",
        "    total_loss = total_loss + loss.item() # Add the current batch's loss (as a Python scalar using .item()) to the 'total_loss' for the epoch.\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\") # After each epoch, print the current epoch number and the average loss for that epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fbZzQT07WIqj"
      },
      "outputs": [],
      "source": [
        "# Define a prediction function that takes the trained 'model', a 'question' string, and an optional 'threshold' for prediction confidence.\n",
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, vocab) # Convert the input 'question' string into its numerical representation using the 'text_to_indices' function and the global 'vocab'.\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0) # Convert the list of numerical indices into a PyTorch tensor and add an extra dimension at the beginning (unsqueeze(0)) to represent the batch dimension (even for a single question).\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor) # Pass the prepared 'question_tensor' through the trained model to get the raw output (logits).\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1) # Apply the softmax function to the model's output (logits) along dimension 1 to convert them into probabilities. These probabilities represent the model's confidence for each word in the vocabulary.\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1) # Find the maximum probability ('value') and its corresponding index ('index') along dimension 1. This 'index' is the predicted word's index in the vocabulary.\n",
        "\n",
        "  if value < threshold: # Check if the confidence (maximum probability) of the predicted word is below a specified 'threshold'.\n",
        "    print(\"I don't know\") # If the confidence is too low, print a message indicating the model is unsure.\n",
        "\n",
        "  print(list(vocab.keys())[index]) # Retrieve the word corresponding to the predicted 'index' from the 'vocab' dictionary (by getting its keys as a list) and print it as the model's answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ2DS-nubk5n",
        "outputId": "7484a0a3-6511-4718-f1c9-4463319219b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "jupiter\n"
          ]
        }
      ],
      "source": [
        "predict(model, \"What is the largest planet in our solar system?\") # Call the 'predict' function with the trained 'model' and a sample question to get an answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pHg7XdBzbnkA",
        "outputId": "872e0e9e-7e08-4e5d-ff13-cb1eb4d9da0d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'paris'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(vocab.keys())[7] # Access the vocabulary dictionary's keys, convert them to a list, and retrieve the word at index 7. This is likely done to demonstrate how to map an index back to a word, or to check a specific word's index."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
